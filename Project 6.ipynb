{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n        <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Analyse search terms on the e-commerce web server\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### In this assignment you will download the search term data set for the e-commerce web server and run analytic queries on it.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Install spark",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!pip3 install pyspark==3.1.2\n!pip install findspark\n\nimport findspark\nfindspark.init()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Pandas is a popular data science package for Python. In this lab, we use Pandas to load a CSV file from disc to a pandas dataframe in memory.\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# pyspark is the Spark API for Python. In this lab, we use pyspark to initialize the spark context. \nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Start session",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Creating a spark context class\nsc = SparkContext()\n\n# Creating a spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark DataFrames basic example\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()\n\nspark",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Download The search term dataset from the below url\n# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv')\ndata.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Load the csv into a spark dataframe",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df = spark.createDataFrame(data)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Print the number of rows and columns\n# Take a screenshot of the code and name it as shape.jpg)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# The number of rows\nnum_rows = df.count()\nprint(\"Number of rows: \", num_rows)\n\n# The number of columns\nnum_columns = len(df.columns)\nprint(\"Number of columns: \", num_columns)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Print the top 5 rows\n# Take a screenshot of the code and name it as top5rows.jpg)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.show(5)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Find out the datatype of the column searchterm?\n# Take a screenshot of the code and name it as datatype.jpg)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.printSchema()\n\nsearchterm_dtype = df.select(\"searchterm\").dtypes[0][1]\nprint(\"Data type of searchterm column:\", searchterm_dtype)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# How many times was the term `gaming laptop` searched?\n# Take a screenshot of the code and name it as gaminglaptop.jpg)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "count = df.filter(df.searchterm == \"gaming laptop\").count()\n\nprint(\"Number of times 'gaming laptop' was searched:\", count)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Print the top 5 most frequently used search terms?\n# Take a screenshot of the code and name it as top5terms.jpg)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "search_counts = df.groupBy(\"searchterm\").count()\nsearch_counts = search_counts.orderBy(\"count\")\n\ntop_5_search_terms = search_counts.limit(5)\ntop_5_search_terms.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# The pretrained sales forecasting model is available at  the below url\n# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Load the sales forecast model.\n# Take a screenshot of the code and name it as loadmodel.jpg)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from pyspark.ml import PipelineModel\nfrom pyspark.ml import Pipeline\n\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Using the sales forecast model, predict the sales for the year of 2023.\n# Take a screenshot of the code and name it as forecast.jpg",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}